# DL_Interview 
. SSE = sum of squared error 
. Precpeptron model= node edges activation function input weights 
. Gradient Descent ... As SSE is parabola, gradient descent is derivatie of err and minimizing it It is steepest path of descent 
. Stochastic Gradient Descent : Is for batch processing on data set and applying GD. 
For SGD the variance over each batch decrease if batch size is large. SO taking a batch size supported by GPU is advisabale. 
